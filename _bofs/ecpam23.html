---
layout: default
title: 2023 ECP Annual Meeting BoF
subtitle: "Exascale Workflows Community: A Post-ECP Roadmap for Workflow Systems and Applications"
event_date: Thursday - January 19, 2023
time: "1:30pm-2:15pm CST"
order: 2
---

<article class="post">
    <header>
        <div class="title">
            <h2>{{page.title}}</h2>
            <p>{{page.subtitle}}</p>
        </div>
        <div class="meta dark" style="background-color: #999; border-top-right-radius: 0.5em; color: #fff">
            <div>
                <p class="date" style="line-height: 1.5em;"><strong>{{page.event_date | date: "%A <br /> %b %d, %Y"
                        }}</strong><br />Founders 3+4</p>
                <p class="time" style="color: #fff">{{page.time}}</p>
            </div>
        </div>
    </header>

    <p>
        Complex workflows have increasingly high computational and I/O demand and are composed of many communicating
        orchestrators, services, and simulations. The ECP ecosystem has observed an increasing pervasiveness of workflow
        systems to handle these classes of complex, distributed applications. The interplay of workflow technologies and
        HPC has been challenged by the fast rise of ML technologies: ML needs to be integrated within workflows to ease
        their development and portability; workflows must benefit from ML to scale and increase efficiency of
        executions; HPC must embrace workflows to democratize access to its resources, as workflow systems should better
        exploit the power of HPC systems; ML must adapt to HCP architectures to scale to real-world large settings, and
        HCP must adjust to ML requirements to provide the required computational resources to scale up to extremely
        large data sets. Furthermore, HPC resource allocation policies and scheduler designs typically provide a simple
        "job" abstraction instead of workflow-aware abstractions. As a result, it is difficult to run exascale workflows
        efficiently and conveniently on HPC systems without extending resource management/scheduling approaches. In this
        BoF, we will bring together researchers and DOE facility representatives from the workflows, HPC, and AI/ML
        communities that work on scientific research questions requiring large-scale, distributed, and AI-heavy
        computing at exascale as well as workflows that allow the integration of (physical) experiments and
        computational facilities. The session will discuss challenges, opportunities, and future pathways, and will seek
        input for a post-ECP community roadmap focused on the sustainability of HPC and AI workflows software and
        applications.
    </p>

    <p>
        Specifically, the BoF session discussions will focus on the following questions:
    <ul>
        <li>In the era of exascale and ML/AI, what are the emerging and future crucial challenges for post-ECP
            workflows?</li>
        <li>Considering workflows sustainability, what are the key constraints and opportunities to attain
            sustainability?</li>
        <li>Which software/technology are essential for enabling sustainable workflows post-ECP?</li>
    </ul>
    </p>


    <h1>Agenda</h1>

    <ul>
        <li style="color: rgb(5, 135, 215)">
            1:30pm-1:40pm &mdash; 
            <a href="/files/bof/bof_ecpam_23_opening_remarks.pdf">Opening remarks</a><br />
            <p style="padding-left: 1em; line-height: 1.2em; color: #666; margin-bottom: 0.5em">
                Rafael Ferreira da Silva – <span style="font-style: italic; color: #999">Oak Ridge National
                    Laboratory</span>
            </p>
        </li>
        <li style="color: rgb(5, 135, 215)">
            1:40pm-2:15pm &mdash; Panel Discussion<br />
            <p style="padding-left: 1em; line-height: 1.2em; color: #666; margin-bottom: 0.5em">
                Shantenu Jha (Moderator) - <span style="font-style: italic; color: #999">Brookhaven National
                    Laboratory</span>
            </p>
            <p style="padding-left: 1em; line-height: 1.2em; color: #666; margin-bottom: 0.5em">
                Katie Antypas - <span style="font-style: italic; color: #999">Lawrence Berkeley National
                    Laboratory</span>
            </p>
            <p style="padding-left: 1em; line-height: 1.2em; color: #666; margin-bottom: 0.5em">
                Todd Gamblin - <span style="font-style: italic; color: #999">Lawrence Livermore National
                    Laboratory</span>
            </p>
            <p style="padding-left: 1em; line-height: 1.2em; color: #666; margin-bottom: 0.5em">
                Andrew Gallo - <span style="font-style: italic; color: #999">GE Research</span>
            </p>
            <p style="padding-left: 1em; line-height: 1.2em; color: #666; margin-bottom: 0.5em">
                Arjun Shankar - <span style="font-style: italic; color: #999">Oak Ridge National Laboratory</span>
            </p>
        </li>
    </ul>

    <br />
    <h3>Supporters</h3>

    <div>
        <a href="https://exaworks.org" target="_blank" style="border-bottom: 0">
            <img src="https://exaworks.org/images/exaworks-name.png" height="25px" /></a>
        &nbsp;&nbsp;&nbsp;&nbsp;
        <a href="https://www.exascaleproject.org/" target="_blank" style="border-bottom: 0">
            <img src="/images/bof/ecp.png" height="30px" /></a>
        &nbsp;&nbsp;&nbsp;&nbsp;
        <a href="https://science.osti.gov/" target="_blank" style="border-bottom: 0">
            <img src="https://science.osti.gov/assets/img/doe-logos/logo.png" height="30px" /></a>
    </div>

    <br />
</article>

<article class="post">
    <h1>Participants Contributions</h1>
    <strong>In the era of exascale and ML/AI, what are the emerging and future crucial challenges for post-ECP workflows?</strong>
    <blockquote>
        <ul style="margin-bottom: 0">
            <li>Managing dynamic workflows at scale</li>
            <li>Near term we need to put in place services and capabilities in data centers that enable data management and movement in a portable way and de-emphasize filesystems as the main orchestration mechanism.</li>
            <li>(1) Support for diverse coupling of HPC and AI/ML components, and integration scenarios without wholesale refactoring of applications. Flexible frameworks that enable a range are needed.
                (2) Simplicity of deployment of ML/AI on HPC</li>
            <li>Data continuum to/from ML/AI workflows and traditional workflows</li>
            <li>Data, data, and data. Locality, provenance, movement and cost</li>
            <li>Cross facility integration; Robust standards for apis and interfaces</li>
            <li>Challenge Problems that integrate HPC Simulations and Measurement/Observations are: Digital Twins, Validation and Verification, Experiment Design or steering. What are the workflows that support these use cases? What are their differences?</li>
            <li>From Tuesdays talk different tasks in a workflow may need to be able to be submitted on different systems</li>
            <li>Leveraging ML/AI to reduce the turnaround time of completing a workflow.</li>
            <li>Interactive, human-in-the-loop model evolution/iteration is a must. How that fits into existing workflow engine designs is an interesting question</li>
            <li>Difficulty providimg infrastructure for workflows that require dependable realtime turnaround</li>
            <li>Interconnection of systems; Standardized APIs; Data management</li>
            <li>One issue is that training data is often generated by physics models. These models take a lot more time and resources than a typical ML model for either training or inference. So there is a “length scale” problem.</li>
            <li>Reproducibility - retain how and where the code was run (environment, parameters, configuration, dependencies, etc)</li>
            <li>Dealing with heterogeneity of compute; Analysis of performance; Finding the shortest path to a solution; Reproducibility of workflows; Policy driven behavior vs technology behaviors</li>
        </ul>
    </blockquote>
    <br />
    <strong>Considering workflows sustainability, what are the key constraints and opportunities to attain sustainability?</strong>
    <blockquote>
        <ul style="margin-bottom: 0">
            <li>Funding specific software vs applications vs workflows</li>
            <li>If we can not have a unified funding stream for sustainability, we should encourage agencies and program managers to encourage participation and collaboration in common software infrastructures and processes.</li>
            <li>Building blocks that existing and future developers can use to customize/extend/ develop their own workflow capabilities.</li>
            <li>A cognizant and consistent workforce that understands the workflow</li>
            <li>Reaching critical mass</li>
            <li>Workflows that cross institutional or organizational domains of ownership/control. We need policies and support from DOE</li>
            <li>Future funding</li>
            <li>Availability of no-code or low-code tools for defining and managing a workflow that lowers the barrier of leveraging workflows.</li>
            <li>The key opportunity is to create a wealth of knowledge and reusable capabilities. With a critical mass of workflows, I foresee a path to autonomous AI/ML-driven exploration of scientific questions. One constraint is that we need to think about how sustain workflows at scale, at a population-level.</li>
            <li>Opportunities - containerized and cloud technology for resilience</li>
            <li>Standardized formats; Portability</li>
            <li>If workflows are complicated enough then managing the decencies becomes a challenge. You need to test all the interdependencies to ensure that the whole workflow keeps working.</li>
            <li>Opportunity: define benchmarks around workflows (and hope this benchmark lives like linpack did); Constraint: to some extent a workflow with science is often something that is implemented to something for the first time ( never done before experiment) the tools required for production workflows vs experimental workflows are not the same</li>
        </ul>
    </blockquote>
    <br />
    <strong>Which software/technology are essential for enabling sustainable workflows post-ECP?</strong>
    <blockquote>
        <ul style="margin-bottom: 0">
            <li>Workflow systems and data management systems</li>
            <li>Cloud and classic-HPC interoperability and portability</li>
            <li>Depends upon workflow applications; in addition to application kernels, it includes libraries, workflow and resource management middleware, automation capabilities, data management software etc.</li>
            <li>Containers</li>
            <li>Collaboration. far more important than point solutions.</li>
            <li>Containers; Standardized apis and interface with a clear governance model</li>
            <li>Automated builds, tools like containers and space</li>
            <li>Package manager, build tools, Python, resource manager, GUI/CLI/API</li>
            <li>There's a need for cyberinfrastructures to enable the curation and maintenance of workflows, and policies for governance for workflows as an enduring institutional resource. There is ongoing work at Sandia on this front.</li>
            <li>Containers, cloud-like services, systems with failovers or ability to burst to cloud</li>
            <li>Support for Resource/Workload Managers; Workflow-aware schedulers</li>
            <li>Ultimately it would be nice if the scale could be flexible. Some steps may need only a couple of nodes others could use thousands. To avoid wasting resources it would be nice if different phases could use different resource allocations.</li>
        </ul>
    </blockquote>
    <br />
</article>